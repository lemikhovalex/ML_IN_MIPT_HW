{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework01: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02 seminar](https://github.com/ml-mipt/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bifCUA727w74"
   },
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Oj_o2Rzx7w76",
    "outputId": "491f6afc-7d6d-4999-869d-81e5f2d4afe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: curl: not found\n",
      "tar (child): ./Train_rev1.csv.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Train_rev1.csv does not exist: 'Train_rev1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-279cfbea49cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tar -xvzf ./Train_rev1.csv.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train_rev1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File Train_rev1.csv does not exist: 'Train_rev1.csv'"
     ]
    }
   ],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "IR1tU2_z8kvb",
    "outputId": "3b792e2c-2a75-49f6-b8b9-ee72c3afaea4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  ...        SourceName\n",
       "0  12612628  ...  cv-library.co.uk\n",
       "1  12612830  ...  cv-library.co.uk\n",
       "2  12612844  ...  cv-library.co.uk\n",
       "3  12613049  ...  cv-library.co.uk\n",
       "4  12613647  ...  cv-library.co.uk\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwN72gd4ycOA"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "# data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UuuKIKfrycOH"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "RUWkpd7PycOQ",
    "outputId": "1b2a182f-adfe-44a5-c8f8-89938cdd5448"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [00:00, 3979.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [01:07, 3537.10it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22e0x6Wg7w8P",
    "outputId": "e9d6811e-5c33-4270-8317-d87ffe8a6fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "23147280-a747-497d-8972-d3edeabc91eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "e85f0494-5964-4a9b-cd0d-55441d0cd198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "8954cf79-324a-472d-f552-03937b8cf7cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "02a0f5ff-7f5e-44a9-8ea8-2c8d34a24eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6LpEQf0ycPD"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTHYCBhD7w81"
   },
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKNl8rmN7w83"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3saUUA17w88"
   },
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXIjo_JA7w9A"
   },
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_G41TB9p7w9B"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuhLMMpv7w9F"
   },
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0YwS6Iy7w9I"
   },
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "1a-HwABV7w9M",
    "outputId": "228ea1a1-47d5-4deb-8263-a3e65752e627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'FullDescription': array([[28344,  2526, 18670, ..., 33642, 22767,   167],\n",
       "        [ 5134,  1894, 28350, ...,   195,     0,    80],\n",
       "        [ 9888, 30762, 11406, ...,     1,     1,     1]], dtype=int32),\n",
       " 'Title': array([[28344,  2532, 18670],\n",
       "        [28350,  8992,     1],\n",
       "        [21980, 30235,  1681]], dtype=int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpPUpSRh7w9R"
   },
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kzWVjY287w9S",
    "outputId": "887860b2-d36a-4911-9191-8e18800833bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2212],\n",
       "        [-0.2443],\n",
       "        [-0.1818]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "t21ioFv57w9W",
    "outputId": "db3f0324-7eac-4d1c-8bd3-cbc43b852bc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'FullDescription': array([[28344,  2526, 18670, ..., 33642, 22767,   167],\n",
       "        [ 5134,  1894, 28350, ...,   195,     0,    80],\n",
       "        [ 9888, 30762, 11406, ...,     1,     1,     1]], dtype=int32),\n",
       " 'Title': array([[28344,  2532, 18670],\n",
       "        [28350,  8992,     1],\n",
       "        [21980, 30235,  1681]], dtype=int32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zlzp7ndk7w9a"
   },
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "3hBDKwOb7w9b",
    "outputId": "ab415b61-f747-400f-85ab-e92544a732d0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = simple_model\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "  for idx, (batch, target) in enumerate(iterate_minibatches(data_train[:25600])):\n",
    "#          # Preprocessing the batch data and target\n",
    "    batch = torch.tensor(batch['FullDescription'], dtype=torch.long)#\n",
    "    target = torch.tensor(target)\n",
    "    \n",
    "    predictions = model(batch)\n",
    "    \n",
    "    predictions = predictions.view(predictions.size(0))\n",
    "    \n",
    "    loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "#          # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "#          # <YOUR CODE HERE>\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "    if (idx+1)%10==0:\n",
    "      clear_output(True)\n",
    "      plt.plot(history,label='loss')\n",
    "      plt.legend()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qRNDiRe7w9f"
   },
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxYIvOCk7w9i"
   },
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0-t8SFJ5LS7"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "50U4eAqr7w9m",
    "outputId": "ca4d6b7d-810f-4f29-ff73-4317e7c68731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/content/network.py'>"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6Vk41Ml7w9q"
   },
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. In should be found out by you.\n",
    "    concat_number_of_features= 3874 #<YOUR CODE HERE> \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjSNXp896k60"
   },
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1jF9HSJ06nKR",
    "outputId": "a478aa38-b61d-4390-c9ee-a79a815df104"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0558],\n",
       "        [0.0528],\n",
       "        [0.0720]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 151,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testing_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7nKh1FQi7w9x",
    "outputId": "19a8c312-47cb-4889-f3fa-fb4be3dc0dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMpa-39V7w90"
   },
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Ah84lGhb7w91",
    "outputId": "5c3392a5-2d56-4834-ba82-7cc74102df9a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training pipeline comes here (almost the same as for the simple_model)\n",
    "#\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "epochs = 1\n",
    "\n",
    "model = network.ThreeInputsNet(n_tokens=len(tokens), \n",
    "                               n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "                               concat_number_of_features= 3874 #<YOUR CODE HERE>\n",
    "                               )\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "  for idx, (batch, target) in enumerate(iterate_minibatches(data_train[:25600])):\n",
    "     # Preprocessing the batch data and target\n",
    "    batch = [\n",
    "             torch.tensor(batch['Title'], dtype=torch.long),\n",
    "             torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
    "             torch.tensor(batch['Categorical'])\n",
    "             ]\n",
    "    target = torch.tensor(target)\n",
    "    predictions = model(batch)\n",
    "    predictions = predictions.view(predictions.size(0))\n",
    "    loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "#          # <YOUR CODE HERE>\n",
    "    history.append(loss.data.numpy())\n",
    "    if (idx+1)%10==0:\n",
    "      clear_output(True)\n",
    "      plt.plot(history,label='loss')\n",
    "      plt.legend()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1vlnc3-7w96"
   },
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "gr2w-EvX7w97",
    "outputId": "0e397cdf-741b-440d-a4d5-846157d64f5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeInputsNet(\n",
       "  (title_emb): Embedding(33795, 64)\n",
       "  (title_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "  (title_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (full_emb): Embedding(33795, 64)\n",
       "  (full_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "  (full_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (inter_dense): Linear(in_features=3874, out_features=128, bias=True)\n",
       "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (fin_ac): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzp0pnby7w-A"
   },
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "0QiZxwvB7w-E",
    "outputId": "70d92823-69f2-4af0-bee9-c63fbd361930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission results:\n",
      "Mean square error: 5.65989\n",
      "Mean absolute error: 1.84378\n",
      "Submission file generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LafFQW487w-H"
   },
   "source": [
    "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Homework_1_three_headed_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
